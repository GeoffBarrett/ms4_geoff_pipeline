{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mountainlab_pytools import mlproc as mlp\n",
    "\n",
    "\n",
    "def bandpass_filter(*, timeseries, timeseries_out, samplerate, freq_min, freq_max, opts={}):\n",
    "    return mlp.runProcess(\n",
    "        'ephys.bandpass_filter',\n",
    "        {\n",
    "            'timeseries': timeseries\n",
    "        }, {\n",
    "            'timeseries_out': timeseries_out\n",
    "        },\n",
    "        {\n",
    "            'samplerate': samplerate,\n",
    "            'freq_min': freq_min,\n",
    "            'freq_max': freq_max\n",
    "        },\n",
    "        opts\n",
    "    )\n",
    "\n",
    "\n",
    "def _mask_artifacts(*, timeseries, timeseries_out, threshold=6, chunk_size=2000, num_write_chunks=150, opts={}):\n",
    "    return mlp.runProcess(\n",
    "        'ephys.mask_out_artifacts',\n",
    "        {\n",
    "            'timeseries': timeseries\n",
    "        },\n",
    "        {\n",
    "            'timeseries_out': timeseries_out\n",
    "        },\n",
    "        {\n",
    "            'threshold': threshold,\n",
    "            'chunk_size': chunk_size,\n",
    "            'num_write_chunks': num_write_chunks,\n",
    "        },\n",
    "        opts\n",
    "    )\n",
    "\n",
    "\n",
    "def _whiten(*, timeseries, timeseries_out, opts={}):\n",
    "    return mlp.runProcess(\n",
    "        'ephys.whiten',\n",
    "        {\n",
    "            'timeseries': timeseries\n",
    "        },\n",
    "        {\n",
    "            'timeseries_out': timeseries_out\n",
    "        },\n",
    "        {},\n",
    "        opts\n",
    "    )\n",
    "\n",
    "\n",
    "def ms4alg_sort(*, timeseries, geom, firings_out, detect_sign, adjacency_radius, detect_threshold, detect_interval,\n",
    "                clip_size, num_workers=os.cpu_count(), opts={}):\n",
    "    pp = {}\n",
    "    pp['detect_sign'] = detect_sign\n",
    "    pp['adjacency_radius'] = adjacency_radius\n",
    "    pp['detect_threshold'] = detect_threshold\n",
    "    pp['clip_size'] = clip_size\n",
    "    pp['detect_interval'] = detect_interval\n",
    "    pp['num_workers'] = num_workers\n",
    "    \n",
    "    inputs = {'timeseries': timeseries}\n",
    "    if geom is not None:\n",
    "        inputs['geom'] = geom\n",
    "\n",
    "    mlp.runProcess(\n",
    "        'ms4alg.sort',\n",
    "        inputs,\n",
    "        {\n",
    "            'firings_out': firings_out\n",
    "        },\n",
    "        pp,\n",
    "        opts\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_cluster_metrics(*, timeseries, firings, metrics_out, samplerate, opts={}):\n",
    "    metrics1 = mlp.runProcess(\n",
    "        'ms3.cluster_metrics',\n",
    "        {\n",
    "            'timeseries': timeseries,\n",
    "            'firings': firings\n",
    "        },\n",
    "        {\n",
    "            'cluster_metrics_out': True\n",
    "        },\n",
    "        {\n",
    "            'samplerate': samplerate\n",
    "        },\n",
    "        opts\n",
    "    )['cluster_metrics_out']\n",
    "    metrics2 = mlp.runProcess(\n",
    "        'ms3.isolation_metrics',\n",
    "        {\n",
    "            'timeseries': timeseries,\n",
    "            'firings': firings\n",
    "        },\n",
    "        {\n",
    "            'metrics_out': True\n",
    "        },\n",
    "        {\n",
    "            'compute_bursting_parents': 'true'\n",
    "        },\n",
    "        opts\n",
    "    )['metrics_out']\n",
    "    return mlp.runProcess(\n",
    "        'ms3.combine_cluster_metrics',\n",
    "        {\n",
    "            'metrics_list': [metrics1, metrics2]\n",
    "        },\n",
    "        {\n",
    "            'metrics_out': metrics_out\n",
    "        },\n",
    "        {},\n",
    "        opts\n",
    "    )\n",
    "\n",
    "\n",
    "def add_curation_tags(*, cluster_metrics, output_filename, firing_rate_thresh=0.05,\n",
    "                      isolation_thresh=0.95, noise_overlap_thresh=0.03, peak_snr_thresh=1.5, opts={}):\n",
    "    # Automated curation\n",
    "    mlp.runProcess(\n",
    "        'pyms.add_curation_tags',\n",
    "        {\n",
    "            'metrics': cluster_metrics\n",
    "        },\n",
    "        {\n",
    "            'metrics_tagged': output_filename\n",
    "        },\n",
    "        {\n",
    "            'firing_rate_thresh': firing_rate_thresh,\n",
    "            'isolation_thresh': isolation_thresh,\n",
    "            'noise_overlap_thresh': noise_overlap_thresh,\n",
    "            'peak_snr_thresh': peak_snr_thresh\n",
    "        },\n",
    "        opts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mountainlab_pytools import mlproc as mlp\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def sort_dataset(*,\n",
    "                 raw_fname=None, filt_fname = None, pre_fname=None, geom_fname=None, params_fname=None,\n",
    "                 firings_out, filt_out_fname='', pre_out_fname='', metrics_out_fname='', masked_out_fname='',\n",
    "                 freq_min=300, freq_max=7000, samplerate=30000, detect_sign=1,\n",
    "                 adjacency_radius=-1, detect_threshold=3, detect_interval=10, clip_size=50,\n",
    "                 firing_rate_thresh=0.05, isolation_thresh=0.95, noise_overlap_thresh=0.03,\n",
    "                 peak_snr_thresh=1.5, mask_artifacts='true', whiten='true',\n",
    "                 mask_threshold=6, mask_chunk_size=2000,\n",
    "                 mask_num_write_chunks=15, num_workers=os.cpu_count()):\n",
    "    \"\"\"\n",
    "    Custom Sorting Pipeline. It will pre-process, sort, and curate (using ms_taggedcuration pipeline).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_fname : INPUT\n",
    "        MxN raw timeseries array (M = #channels, N = #timepoints). If you input this it will pre-process the data.\n",
    "    filt_fname : INPUT\n",
    "        MxN raw timeseries array (M = #channels, N = #timepoints). This input contains data that has already been filtered.\n",
    "    pre_fname : INPUT\n",
    "        MxN pre-processed array timeseries array (M = #channels, N = #timepoints). This is if you want to analyze already pre-processed data.\n",
    "    geom_fname : INPUT\n",
    "        (Optional) geometry file (.csv format).\n",
    "    params_fname : INPUT\n",
    "        (Optional) parameter file (.json format), where the key is the any of the parameters for this pipeline. Any values in this .json file will overwrite any defaults.\n",
    "\n",
    "    firings_out : OUTPUT\n",
    "        The filename that will contain the spike data (.mda file), default to '/firings.mda'\n",
    "    filt_out_fname : OUTPUT\n",
    "        Optional filename for the filtered data (just filtered, no whitening).\n",
    "    masked_out_fname : OUTPUT\n",
    "        Optional filename for the masked_data.\n",
    "    pre_out_fname : OUTPUT\n",
    "        Optional filename for the pre-processed data (filtered and whitened).\n",
    "    metrics_out_fname : OUTPUT\n",
    "        The optional  output filename (.json) for the metrics that will be computed for each unit.\n",
    "\n",
    "    samplerate : float\n",
    "        (Optional) The sampling rate in Hz\n",
    "    freq_min : float\n",
    "        (Optional) The lower endpoint of the frequency band (Hz)\n",
    "    freq_max : float\n",
    "        (Optional) The upper endpoint of the frequency band (Hz)\n",
    "    adjacency_radius : float\n",
    "        (Optional) Radius of local sorting neighborhood, corresponding to the geometry file (same units). 0 means each channel is sorted independently. -1 means all channels are included in every neighborhood.\n",
    "    detect_sign : int\n",
    "        (Optional) Use 1, -1, or 0 to detect positive peaks, negative peaks, or both, respectively\n",
    "    detect_threshold : float\n",
    "        (Optional) Threshold for event detection, corresponding to the input file. So if the input file is normalized to have noise standard deviation 1 (e.g., whitened), then this is in units of std. deviations away from the mean.\n",
    "    detect_interval : int\n",
    "        (Optional) The minimum number of timepoints between adjacent spikes detected in the same channel neighborhood.\n",
    "    clip_size : int\n",
    "        (Optional) Size of extracted clips or snippets, used throughout\n",
    "    firing_rate_thresh : float64\n",
    "        (Optional) firing rate must be above this\n",
    "    isolation_thresh : float64\n",
    "        (Optional) isolation must be above this\n",
    "    noise_overlap_thresh : float64\n",
    "        (Optional) noise_overlap_thresh must be below this\n",
    "    peak_snr_thresh : float64\n",
    "        (Optional) peak snr must be above this\n",
    "    mask_artifacts : str\n",
    "        (Optional) if set to 'true', it will mask the large amplitude artifacts, if 'false' it will not.\n",
    "    whiten : str\n",
    "        (Optional) if set to 'true', it will whiten the signal (assuming the input is raw_fname, if 'false' it will not.\n",
    "    mask_threshold : int\n",
    "        (Optional) Number of standard deviations away from the mean RSS for the chunk to be considered as artifact.\n",
    "    mask_chunk_size: int\n",
    "        This chunk size will be the number of samples that will be set to zero if the RSS of this chunk is above threshold.\n",
    "    mask_num_write_chunks: int\n",
    "        How many mask_chunks will be simultaneously written to mask_out_fname (default of 150).\n",
    "    num_workers : int\n",
    "        (Optional) Number of simultaneous workers (or processes). The default is multiprocessing.cpu_count().\n",
    "    \"\"\"\n",
    "\n",
    "    if mask_artifacts == 'true':\n",
    "        mask = True\n",
    "    elif mask_artifacts == 'false':\n",
    "        mask_artifacts = False\n",
    "    else:\n",
    "        raise Exception(\"mask_artifacts must be set to 'true' or 'false'!\")\n",
    "\n",
    "    if whiten == 'true':\n",
    "        whiten = True\n",
    "    elif whiten == 'false':\n",
    "        whiten = False\n",
    "    else:\n",
    "        raise Exception(\"whiten must be set to 'true' or 'false'!\")\n",
    "\n",
    "    # if you do not provide an input, it will set the value as an empty string via mountainlab\n",
    "\n",
    "    # TODO: find a more pythonic way to do this\n",
    "    \n",
    "    if raw_fname == '':\n",
    "        raw_fname = None\n",
    "    \n",
    "    if filt_fname == '':\n",
    "        filt_fname = None\n",
    "    \n",
    "    if masked_out_fname == '':\n",
    "        masked_out_fname = None\n",
    "\n",
    "    if pre_out_fname == '':\n",
    "        pre_out_fname = None\n",
    "\n",
    "    if filt_out_fname == '':\n",
    "        filt_out_fname = None\n",
    "\n",
    "    if metrics_out_fname == '':\n",
    "        metrics_out_fname = None\n",
    "\n",
    "    if pre_fname == '':\n",
    "        pre_fname = None\n",
    "\n",
    "    if geom_fname == '':\n",
    "        geom_fname = None\n",
    "\n",
    "    if params_fname == '':\n",
    "        params_fname = None\n",
    "\n",
    "    if firings_out == '':\n",
    "        firings_out = None\n",
    "\n",
    "    # END TODO\n",
    "\n",
    "    if raw_fname is None and pre_fname is None and filt_fname is None:\n",
    "        raise Exception('You must input a raw_fname, filt_fname, or a pre_fname!')\n",
    "\n",
    "    if raw_fname is not None and pre_fname is not None:\n",
    "        raise Exception('You defined both the raw_fname and the pre_fname, can only use one!')\n",
    "\n",
    "    params = {'freq_min': freq_min,\n",
    "              'freq_max': freq_max,\n",
    "              'samplerate': samplerate,\n",
    "              'detect_sign': detect_sign,\n",
    "              'adjacency_radius': adjacency_radius,\n",
    "              'detect_threshold': detect_threshold,\n",
    "              'detect_interval': detect_interval,\n",
    "              'clip_size': clip_size,\n",
    "              'firing_rate_thresh':  firing_rate_thresh,\n",
    "              'isolation_thresh': isolation_thresh,\n",
    "              'noise_overlap_thresh': noise_overlap_thresh,\n",
    "              'peak_snr_thresh': peak_snr_thresh,\n",
    "              'mask_threshold': mask_threshold,\n",
    "              'mask_chunk_size': mask_chunk_size,\n",
    "              'mask_num_write_chunks': mask_num_write_chunks,\n",
    "              'mask_artifacts': mask_artifacts,\n",
    "              'num_workers': num_workers,\n",
    "    }\n",
    "\n",
    "    if params_fname is not None:\n",
    "        if os.path.exists(params_fname):\n",
    "            ds_params = read_dataset_params(params_fname)\n",
    "\n",
    "        # override the default parameters\n",
    "        for key, value in ds_params.items():\n",
    "            params[key] = value\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if raw_fname is not None:\n",
    "        # no pre-processing has done, so perform the pre-processing\n",
    "        if not os.path.exists(raw_fname):\n",
    "            raise Exception('The following timeseries does not exist: %s!' % raw_fname)\n",
    "\n",
    "        output_dir = os.path.dirname(raw_fname)\n",
    "\n",
    "        if filt_out_fname is None:\n",
    "            filt_out_fname = output_dir + '/filt.mda.prv'\n",
    "\n",
    "        # Bandpass filter\n",
    "        bandpass_filter(\n",
    "            timeseries=raw_fname,\n",
    "            timeseries_out=filt_out_fname,\n",
    "            samplerate=params['samplerate'],\n",
    "            freq_min=params['freq_min'],\n",
    "            freq_max=params['freq_max'],\n",
    "            # opts=opts\n",
    "        )\n",
    "        \n",
    "        if params['mask_artifacts']:\n",
    "            # if the user decided to mask the artifacts, do so\n",
    "            if masked_out_fname is None:\n",
    "                masked_out_fname = output_dir + '/masked.mda.prv'\n",
    "            \n",
    "            _mask_artifacts(\n",
    "                timeseries=filt_out_fname,\n",
    "                timeseries_out=masked_out_fname,\n",
    "                threshold=params['mask_threshold'],\n",
    "                chunk_size=params['mask_chunk_size'],\n",
    "                num_write_chunks=params['mask_num_write_chunks'],\n",
    "                # opts=opts\n",
    "            )\n",
    "\n",
    "            whiten_input = masked_out_fname\n",
    "\n",
    "        else:\n",
    "            # otherwise use the bandpassed data as an input\n",
    "            whiten_input = filt_out_fname\n",
    "\n",
    "        if whiten:\n",
    "            if pre_out_fname is None:\n",
    "                pre_out_fname = output_dir + '/pre.mda.prv'\n",
    "\n",
    "            # Whiten\n",
    "            _whiten(\n",
    "                timeseries=whiten_input,\n",
    "                timeseries_out=pre_out_fname,\n",
    "                # opts=opts\n",
    "            )\n",
    "\n",
    "            sort_fname = pre_out_fname\n",
    "        else:\n",
    "            sort_fname = whiten_input\n",
    "\n",
    "    elif filt_fname is not None:\n",
    "        # then the data has already been filtered so just mask artifacts/whiten if desired\n",
    "        \n",
    "        if not os.path.exists(filt_fname):\n",
    "            raise Exception('The following timeseries does not exist: %s!' % filt_fname)\n",
    "            \n",
    "        output_dir = os.path.dirname(filt_fname)\n",
    "            \n",
    "        if params['mask_artifacts']:\n",
    "            # if the user decided to mask the artifacts, do so\n",
    "            if masked_out_fname is None:\n",
    "                masked_out_fname = output_dir + '/masked.mda.prv'\n",
    "\n",
    "            _mask_artifacts(\n",
    "                timeseries=filt_fname,\n",
    "                timeseries_out=masked_out_fname,\n",
    "                threshold=params['mask_threshold'],\n",
    "                chunk_size=params['mask_chunk_size'],\n",
    "                num_write_chunks=params['mask_num_write_chunks'],\n",
    "                # opts=opts\n",
    "            )\n",
    "\n",
    "            whiten_input = masked_out_fname\n",
    "\n",
    "        else:\n",
    "            # otherwise use the filtered data as an input\n",
    "            whiten_input = filt_fname\n",
    "\n",
    "        if whiten:\n",
    "            if pre_out_fname is None:\n",
    "                pre_out_fname = output_dir + '/pre.mda.prv'\n",
    "\n",
    "            # Whiten\n",
    "            _whiten(\n",
    "                timeseries=whiten_input,\n",
    "                timeseries_out=pre_out_fname,\n",
    "                # opts=opts\n",
    "            )\n",
    "\n",
    "            sort_fname = pre_out_fname\n",
    "        else:\n",
    "            sort_fname = whiten_input\n",
    "        \n",
    "    else:\n",
    "        # then the data has alreayd been pre-processed as the pre_fname is the one defined\n",
    "        if not os.path.exists(pre_fname):\n",
    "            raise Exception('The following timeseries does not exist: %s!' % pre_fname)\n",
    "\n",
    "        output_dir = os.path.dirname(pre_fname)\n",
    "        sort_fname = pre_fname\n",
    "\n",
    "    # Sort\n",
    "\n",
    "    if firings_out is None:\n",
    "        firings_out = output_dir + '/firings.mda'\n",
    "\n",
    "    ms4alg_sort(\n",
    "        timeseries=sort_fname,\n",
    "        geom=geom_fname,\n",
    "        firings_out=firings_out,\n",
    "        adjacency_radius=params['adjacency_radius'],\n",
    "        detect_sign=params['detect_sign'],\n",
    "        detect_threshold=params['detect_threshold'],\n",
    "        detect_interval=params['detect_interval'],\n",
    "        clip_size=params['clip_size'],\n",
    "        num_workers=params['num_workers'],\n",
    "        # opts=opts\n",
    "    )\n",
    "\n",
    "    temp_metrics = output_dir + '/temp_metrics.json'\n",
    "\n",
    "    if metrics_out_fname is None:\n",
    "        metrics_out_fname = output_dir + '/cluster_metrics.json'\n",
    "\n",
    "    # Compute cluster metrics\n",
    "    compute_cluster_metrics(\n",
    "        timeseries=sort_fname,\n",
    "        firings=firings_out,\n",
    "        metrics_out=temp_metrics,\n",
    "        samplerate=params['samplerate'],\n",
    "        # opts=opts\n",
    "    )\n",
    "    \n",
    "    add_curation_tags(cluster_metrics=temp_metrics,\n",
    "                      output_filename=metrics_out_fname,\n",
    "                      firing_rate_thresh=params['firing_rate_thresh'],\n",
    "                      isolation_thresh=params['isolation_thresh'],\n",
    "                      noise_overlap_thresh=params['noise_overlap_thresh'],\n",
    "                      peak_snr_thresh=params['peak_snr_thresh'],\n",
    "                      # opts=opts\n",
    "                    )\n",
    "\n",
    "    os.remove(temp_metrics)\n",
    "    return True\n",
    "\n",
    "def read_dataset_params(params_fname):\n",
    "    params_fname = mlp.realizeFile(params_fname)\n",
    "    if not os.path.exists(params_fname):\n",
    "        raise Exception('Dataset parameter file does not exist: ' + params_fname)\n",
    "    with open(params_fname) as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sub(string, sub):\n",
    "    '''finds all instances of a substring within a string and outputs a list of indices'''\n",
    "    result = []\n",
    "    k = 0\n",
    "    while k < len(string):\n",
    "        k = string.find(sub, k)\n",
    "        if k == -1:\n",
    "            return result\n",
    "        else:\n",
    "            result.append(k)\n",
    "            k += 1  # change to k += len(sub) to not search overlapping results\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_ubuntu_path(filepath):\n",
    "    # get the drive letter\n",
    "\n",
    "    drive_letter_i = filepath.find(':/')\n",
    "\n",
    "    if drive_letter_i == -1:\n",
    "        drive_letter_i = filepath.find(':\\\\')\n",
    "\n",
    "    drive_letter = filepath[:drive_letter_i].lower()\n",
    "\n",
    "    i = 1\n",
    "    while drive_letter_i + i == '/':\n",
    "        i += 1\n",
    "\n",
    "    remaining_path = filepath[drive_letter_i + i + 1:]\n",
    "    linux_path = '/mnt/%s/%s' % (drive_letter, remaining_path)\n",
    "    \n",
    "    # add single quotes so linux can understand the special characters\n",
    "    if '(' in linux_path or ')' in linux_path:\n",
    "        linux_path = \"'%s'\" % linux_path\n",
    "\n",
    "    return os.path.normpath((linux_path)).replace('\\\\', '/')\n",
    "\n",
    "def get_windows_filename(filename):\n",
    "    # remove the single quotes if added\n",
    "    if filename[0] == \"'\" and filename[-1] == \"'\":\n",
    "        filename = filename[1:-1]\n",
    "\n",
    "    filename_split = filename.split('/')\n",
    "    mnt_i = np.where(np.array(filename_split) == 'mnt')[0][0]\n",
    "\n",
    "    drive_letter = filename_split[mnt_i + 1].upper()\n",
    "\n",
    "    remaining = '\\\\'.join(list(filename_split[mnt_i + 2:]))\n",
    "\n",
    "    return '%s:\\\\%s' % (drive_letter, remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T1_filt.mda\n",
      "/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_filt.mda\n",
      "/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T3_filt.mda\n",
      "/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T4_filt.mda\n"
     ]
    }
   ],
   "source": [
    "# directory = get_ubuntu_path('E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\b6_march_18_1')\n",
    "# directory = get_ubuntu_path('E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\b6_august_18_1\\\\SimpleCircularTrack')\n",
    "directory = get_ubuntu_path('E:\\\\Apollo_D_Drive\\\\data\\\\MSData\\\\whatever')\n",
    "# directory = get_ubuntu_path('E:\\\\Apollo_D_Drive\\\\data\\VirtualMazeData\\\\b6_august_18_2\\\\NoiseTesting')\n",
    "# directory = get_ubuntu_path('E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\b6_august_18_2\\\\SimpleCircularTrack')\n",
    "\n",
    "raw_fnames = [os.path.join(directory, file) for file in os.listdir(directory) if '_raw.mda' in file]\n",
    "filt_fnames = [os.path.join(directory, file) for file in os.listdir(directory) if '_filt.mda' in file]\n",
    "\n",
    "for file in raw_fnames:\n",
    "    print(file)\n",
    "    \n",
    "print('-----------------------')\n",
    "\n",
    "for file in filt_fnames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Apollo_D_Drive\\data\\MSData\\whatever\\20181001-1050-1-raw-downstairs_T2_filt.mda\n"
     ]
    }
   ],
   "source": [
    "#tint = False\n",
    "tint = True\n",
    "\n",
    "file_index = 1\n",
    "\n",
    "if tint:\n",
    "\n",
    "    filt_fname = get_windows_filename(filt_fnames[file_index])\n",
    "    print(filt_fname)\n",
    "\n",
    "    mda_basename = os.path.splitext(filt_fname)[0]\n",
    "    mda_basename = mda_basename[:find_sub(mda_basename, '_')[-1]]\n",
    "\n",
    "    masked_out_fname = get_ubuntu_path(mda_basename + '_masked.mda')\n",
    "    firings_out = get_ubuntu_path(mda_basename + '_firings.mda')\n",
    "    # filt_out_fname = get_ubuntu_path(mda_basename + '_filt.mda')\n",
    "    pre_out_fname = get_ubuntu_path(mda_basename + '_pre.mda')\n",
    "    metrics_out_fname = get_ubuntu_path(mda_basename + '_metrics.json')\n",
    "\n",
    "    filt_fname = get_ubuntu_path(filt_fname)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raw_fname = get_windows_filename(raw_fnames[file_index])\n",
    "    print(raw_fname)\n",
    "\n",
    "    mda_basename = os.path.splitext(raw_fname)[0]\n",
    "    mda_basename = mda_basename[:find_sub(mda_basename, '_')[-1]]\n",
    "\n",
    "    masked_out_fname = get_ubuntu_path(mda_basename + '_masked.mda')\n",
    "    firings_out = get_ubuntu_path(mda_basename + '_firings.mda')\n",
    "    filt_out_fname = get_ubuntu_path(mda_basename + '_filt.mda')\n",
    "    pre_out_fname = get_ubuntu_path(mda_basename + '_pre.mda')\n",
    "    metrics_out_fname = get_ubuntu_path(mda_basename + '_metrics.json')\n",
    "\n",
    "    raw_fname = get_ubuntu_path(raw_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: 20181001-1050-1-raw-downstairs_T2_filt.mda \n",
      "whiten: true\n",
      "Fs: 48000\n",
      "Tint: true\n",
      "threshold: 3\n"
     ]
    }
   ],
   "source": [
    "if tint:\n",
    "    samplerate=int(48e3)\n",
    "else:\n",
    "    samplerate=int(24e3)\n",
    "    # samplerate=int(30e3)\n",
    "    pass\n",
    "\n",
    "# whiten='false'\n",
    "whiten='true'\n",
    "detect_interval=10\n",
    "detect_sign=0\n",
    "\n",
    "if whiten == 'true':\n",
    "    detect_threshold=3\n",
    "else:\n",
    "    detect_threshold=30\n",
    "    \n",
    "freq_min=300\n",
    "freq_max=6000\n",
    "mask_threshold=6\n",
    "masked_chunk_size = int(samplerate/10)\n",
    "mask_num_write_chunks=100\n",
    "clip_size=50\n",
    "\n",
    "if tint:\n",
    "    print('filename: %s ' % os.path.basename(filt_fname))\n",
    "else:\n",
    "    print('filename: %s '% os.path.basename(raw_fname))\n",
    "    \n",
    "print('whiten: %s' % whiten)\n",
    "print('Fs: %d' % samplerate)\n",
    "print('Tint: %s' % (str(tint).lower()))\n",
    "print('threshold: %d' % detect_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING: ml-run-process ephys.mask_out_artifacts --inputs timeseries:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_filt.mda --parameters chunk_size:4800 num_write_chunks:100 threshold:6 --outputs timeseries_out:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: c3e5a94b0d47cc5e5c0b32810878e3ac2c282a1c\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/bin/python3 /root/conda/envs/mlab2/etc/mountainlab/packages/ml_ephys/preprocessing/preprocessing.py.mp ephys.mask_out_artifacts --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_c3e5a94b0d_u41ZW8 --timeseries=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_c3e5a94b0d_u41ZW8/input_timeseries_r2M4EOG3.mda --timeseries_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_c3e5a94b0d_u41ZW8/output_timeseries_out.mda --chunk_size=4800 --num_write_chunks=100 --threshold=6\u001b[0m\n",
      "\u001b[34mFor channel 0: mean=393786.23, stdev=16281.81, chunk size = 4800\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFor channel 1: mean=307661.42, stdev=7866.28, chunk size = 4800\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFor channel 2: mean=336519.22, stdev=9328.98, chunk size = 4800\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFor channel 3: mean=303179.37, stdev=7740.05, chunk size = 4800\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mUsing 99.90% of all timepoints.\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mElapsed time for processor ephys.mask_out_artifacts: 4.733 sec\u001b[0m\n",
      "\u001b[34mFinalizing output timeseries_out\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ephys.whiten --inputs timeseries:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_masked.mda --parameters --outputs timeseries_out:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: a6ad5c56f5214b29de2d0bb320c0a7aaaf9d7da8\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"timeseries_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/bin/python3 /root/conda/envs/mlab2/etc/mountainlab/packages/ml_ephys/preprocessing/preprocessing.py.mp ephys.whiten --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_a6ad5c56f5_LzkGOM --timeseries=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_a6ad5c56f5_LzkGOM/input_timeseries_HrmXafEE.mda --timeseries_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_a6ad5c56f5_LzkGOM/output_timeseries_out.mda\u001b[0m\n",
      "\u001b[34mChunk size: 300000, Num chunks: 49, Num processes: 12\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mElapsed time for processor ephys.whiten: 4.328 sec\u001b[0m\n",
      "\u001b[34mFinalizing output timeseries_out\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ms4alg.sort --inputs timeseries:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda --parameters adjacency_radius:-1 clip_size:50 detect_interval:10 detect_sign:0 detect_threshold:3 num_workers:12 --outputs firings_out:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[31m/root/conda/envs/mlab2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[31mreturn f(*args, **kwds)\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34mProcess signature: 0a2109a2b044602d6ad613d61db3c1cd0545cae5\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"firings_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"firings_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/bin/python3 /root/conda/envs/mlab2/etc/mountainlab/packages/ml_ms4alg/ms4alg_spec.py.mp ms4alg.sort --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_0a2109a2b0_HhWdgA --timeseries=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_0a2109a2b0_HhWdgA/input_timeseries_Flwn3kT7.mda --geom= --firings_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_0a2109a2b0_HhWdgA/output_firings_out.mda --adjacency_radius=-1 --clip_size=50 --detect_interval=10 --detect_sign=0 --detect_threshold=3 --num_workers=12\u001b[0m\n",
      "\u001b[34mUsing tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_0a2109a2b0_HhWdgA\u001b[0m\n",
      "\u001b[34mPreparing /mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_0a2109a2b0_HhWdgA/timeseries.hdf5...\u001b[0m\n",
      "\u001b[34mPreparing neighborhood sorters...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mDetecting events on channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mDetecting events on channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mDetecting events on channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mDetecting events on channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mClustering for channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mClustering for channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mClustering for channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34mClustering for channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34mComputing templates for channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34mComputing templates for channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34mComputing templates for channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34mComputing templates for channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mRe-assigning events for channel 2 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mRe-assigning events for channel 4 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mRe-assigning events for channel 1 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mRe-assigning events for channel 3 (phase1)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 1 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 4 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 2 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mComputing PCA features for channel 3 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mClustering for channel 4 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mClustering for channel 2 (phase2)...\u001b[0m\n",
      "\u001b[34mClustering for channel 1 (phase2)...\u001b[0m\n",
      "\u001b[34mClustering for channel 3 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 4 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 2 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 1 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mFound 2 clusters for channel 3 (phase2)...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mPreparing output...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mWriting firings file...\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mDone.\u001b[0m\n",
      "\u001b[34m\u001b[0m\n",
      "\u001b[34mElapsed time for processor ms4alg.sort: 10.907 sec\u001b[0m\n",
      "\u001b[34mFinalizing output firings_out\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING: ml-run-process ms3.cluster_metrics --inputs firings:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda timeseries:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda --parameters samplerate:48000 --outputs cluster_metrics_out:/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: 01d6244ac39272b4389f911bcd0cbe9e3e4ce0ff\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"cluster_metrics_out\":\"/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c.prv\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c.prv\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"cluster_metrics_out\":\"/mnt/e/Apollo_D_Drive/MountainSortTempJs/output_01d6244ac39272b4389f911bcd0cbe9e3e4ce0ff_cluster_metrics_out.output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/MountainSortTempJs/output_01d6244ac39272b4389f911bcd0cbe9e3e4ce0ff_cluster_metrics_out.output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/etc/mountainlab/packages/ms3.mp ms3.cluster_metrics --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_01d6244ac3_CUMk1h --firings=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_01d6244ac3_CUMk1h/input_firings_26S5iwFE.mda --timeseries=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_01d6244ac3_CUMk1h/input_timeseries_FqzLOpbT.mda --cluster_metrics_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_01d6244ac3_CUMk1h/output_cluster_metrics_out.output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c --samplerate=48000\u001b[0m\n",
      "\u001b[34mElapsed time for processor ms3.cluster_metrics: 0.07 sec\u001b[0m\n",
      "\u001b[34mFinalizing output cluster_metrics_out\u001b[0m\n",
      "\u001b[34m[ Creating output prv for cluster_metrics_out ... ]\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ms3.isolation_metrics --inputs firings:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_firings.mda timeseries:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_pre.mda --parameters compute_bursting_parents:true --outputs metrics_out:/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0.prv\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[31mStarting p_isolation_metrics\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[31mComputing cluster metrics...\u001b[0m\n",
      "\u001b[34mProcess signature: 019f8a478c5fed0c7b69f2631bf60b7afd9b8b1c\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[31mComputing templates...\u001b[0m\n",
      "\u001b[34m{\"metrics_out\":\"/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0.prv\"}\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0.prv\u001b[0m\n",
      "\u001b[31mDetermining pairs to compare...\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m{\"metrics_out\":\"/mnt/e/Apollo_D_Drive/MountainSortTempJs/output_019f8a478c5fed0c7b69f2631bf60b7afd9b8b1c_metrics_out.output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0\"}\u001b[0m\n",
      "\u001b[31mComputing bursting parents...\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[31mpreparing clusters array\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[31mWriting output...\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/MountainSortTempJs/output_019f8a478c5fed0c7b69f2631bf60b7afd9b8b1c_metrics_out.output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/etc/mountainlab/packages/ms3.mp ms3.isolation_metrics --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_019f8a478c_ML59yc --firings=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_019f8a478c_ML59yc/input_firings_KTU3QjeA.mda --timeseries=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_019f8a478c_ML59yc/input_timeseries_Dnqz6TK2.mda --metrics_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_019f8a478c_ML59yc/output_metrics_out.output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0 --pair_metrics_out= --compute_bursting_parents=true\u001b[0m\n",
      "\u001b[34mElapsed time for processor ms3.isolation_metrics: 1.282 sec\u001b[0m\n",
      "\u001b[34mFinalizing output metrics_out\u001b[0m\n",
      "\u001b[34m[ Creating output prv for metrics_out ... ]\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process ms3.combine_cluster_metrics --inputs metrics_list:/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c.prv metrics_list:/mnt/e/Apollo_D_Drive/MountainSortTempJs/mountainlab/tmp_short_term/output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0.prv --parameters --outputs metrics_out:/mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: bef6f149a05da2cc790ec784252763c0e187d15a\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"metrics_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"metrics_out\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/etc/mountainlab/packages/ms3.mp ms3.combine_cluster_metrics --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_bef6f149a0_31q4Pi --metrics_list=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_bef6f149a0_31q4Pi/input_metrics_list-0_HmnZQpAJ.output_cluster_metrics_out_0a999ba82efa122cf04a229ecdd8aad35af64e2c --metrics_list=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_bef6f149a0_31q4Pi/input_metrics_list-1_BlMUw3UK.output_metrics_out_c4c273685cc14448eebad6e72fe14779ed7c98f0 --metrics_out=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_bef6f149a0_31q4Pi/output_metrics_out.json\u001b[0m\n",
      "\u001b[34mElapsed time for processor ms3.combine_cluster_metrics: 0.084 sec\u001b[0m\n",
      "\u001b[34mFinalizing output metrics_out\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n",
      "RUNNING: ml-run-process pyms.add_curation_tags --inputs metrics:/mnt/e/Apollo_D_Drive/data/MSData/whatever/temp_metrics.json --parameters firing_rate_thresh:0.05 isolation_thresh:0.95 noise_overlap_thresh:0.03 peak_snr_thresh:1.5 --outputs metrics_tagged:/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_metrics.json\n",
      "\u001b[34m[ Getting processor spec... ]\u001b[0m\n",
      "\u001b[34m[ Checking inputs and substituting prvs ... ]\u001b[0m\n",
      "\u001b[34m[ Computing process signature ... ]\u001b[0m\n",
      "\u001b[34mProcess signature: 89a1a089eaf38262ddc80365b5430f04df718dc6\u001b[0m\n",
      "\u001b[34m[ Checking outputs... ]\u001b[0m\n",
      "\u001b[34m{\"metrics_tagged\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_metrics.json\"}\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_metrics.json\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m{\"metrics_tagged\":\"/mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_metrics.json\"}\u001b[0m\n",
      "\u001b[34m[ Checking process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Creating temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Creating links to input files... ]\u001b[0m\n",
      "\u001b[34m[ Preparing temporary outputs... ]\u001b[0m\n",
      "\u001b[34mProcessing ouput - /mnt/e/Apollo_D_Drive/data/MSData/whatever/20181001-1050-1-raw-downstairs_T2_metrics.json\u001b[0m\n",
      "\u001b[34mfalse\u001b[0m\n",
      "\u001b[34m[ Initializing process ... ]\u001b[0m\n",
      "\u001b[34m[ Running ... ] /root/conda/envs/mlab2/bin/python3 /root/conda/envs/mlab2/etc/mountainlab/packages/franklab_mstaggedcuration/python/tagged_curation.py pyms.add_curation_tags --_tempdir=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_89a1a089ea_iNdKi7 --metrics=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_89a1a089ea_iNdKi7/input_metrics_ReNfBOeF.json --metrics_tagged=/mnt/e/Apollo_D_Drive/MountainSortTempJs/tempdir_89a1a089ea_iNdKi7/output_metrics_tagged.json --firing_rate_thresh=0.05 --isolation_thresh=0.95 --noise_overlap_thresh=0.03 --peak_snr_thresh=1.5\u001b[0m\n",
      "\u001b[34mElapsed time for processor pyms.add_curation_tags: 0.237 sec\u001b[0m\n",
      "\u001b[34mFinalizing output metrics_tagged\u001b[0m\n",
      "\u001b[34m[ Saving to process cache ... ]\u001b[0m\n",
      "\u001b[34m[ Removing temporary directory ... ]\u001b[0m\n",
      "\u001b[34m[ Done. ]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if tint:\n",
    "    sort_dataset(filt_fname=filt_fname, pre_out_fname=pre_out_fname, \n",
    "                 metrics_out_fname=metrics_out_fname, firings_out=firings_out, masked_out_fname=masked_out_fname,\n",
    "                 samplerate=samplerate, detect_interval=detect_interval, detect_sign=detect_sign, \n",
    "                 detect_threshold=detect_threshold, freq_min=freq_min, freq_max=freq_max, mask_threshold=mask_threshold, \n",
    "                 mask_chunk_size=masked_chunk_size, mask_num_write_chunks=mask_num_write_chunks, whiten=whiten, clip_size=clip_size\n",
    "                )\n",
    "else:\n",
    "    sort_dataset(raw_fname=raw_fname, filt_out_fname=filt_out_fname, pre_out_fname=pre_out_fname, \n",
    "                 metrics_out_fname=metrics_out_fname, firings_out=firings_out, masked_out_fname=masked_out_fname,\n",
    "                 samplerate=samplerate, detect_interval=detect_interval, detect_sign=detect_sign, \n",
    "                 detect_threshold=detect_threshold, freq_min=freq_min, freq_max=freq_max, mask_threshold=mask_threshold, \n",
    "                 mask_chunk_size=masked_chunk_size, mask_num_write_chunks=mask_num_write_chunks, whiten=whiten, clip_size=clip_size\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
